{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 評価手法\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#データの読み込み\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submit.csv', header=None)\n",
    "\n",
    "train['horsepower'] = train.replace('?', np.nan)\n",
    "train['horsepower'] = train['horsepower'].fillna(train['horsepower'].mean())\n",
    "\n",
    "test['horsepower'] = test.replace('?', np.nan)\n",
    "test['horsepower'] = test['horsepower'].fillna(test['horsepower'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency = train[train['mpg'] < 20]\n",
    "efficiency_car = efficiency['car name'].unique()\n",
    "unefficiency = train[train['mpg'] > 35]\n",
    "unefficiency_car = unefficiency['car name'].unique()\n",
    "train['efficiency'] = train['car name'].apply(lambda x : 1 if x in efficiency_car else 0)\n",
    "train['unefficiency'] = train['car name'].apply(lambda x : 1 if x in unefficiency_car else 0)\n",
    "\n",
    "test['efficiency'] = test['car name'].apply(lambda x : 1 if x in efficiency_car else 0)\n",
    "test['unefficiency'] = test['car name'].apply(lambda x : 1 if x in unefficiency_car else 0)\n",
    "def if_car(x):\n",
    "    if \"amc\" in x:\n",
    "        return 'amc'\n",
    "    elif \"buick\" in x:\n",
    "        return 'buick'\n",
    "    elif \"chevrolet\" in x:\n",
    "        return 'chevrolet'\n",
    "    elif \"datsun\" in x:\n",
    "        return 'datsun'\n",
    "    elif \"dodge\" in x:\n",
    "        return 'dodge'\n",
    "    elif \"fiat\" in x:\n",
    "        return 'fiat'\n",
    "    elif \"ford\" in x:\n",
    "        return 'ford'\n",
    "    elif \"mercury\" in x:\n",
    "        return 'mercury'\n",
    "    elif \"opel\" in x:\n",
    "        return 'opel'\n",
    "    elif \"peugeot\" in x:\n",
    "        return 'peugeot'\n",
    "    elif \"plymouth\" in x:\n",
    "        return 'plymouth'\n",
    "    elif \"pontiac\" in x:\n",
    "        return 'pontiac'\n",
    "    elif \"toyota\" in x:\n",
    "        return 'toyota'\n",
    "    elif \"volkswagen\" in x:\n",
    "        return 'volkswagen'\n",
    "    elif \"vw\" in x:\n",
    "        return 'vw'\n",
    "    else:\n",
    "        return 'other_bland'\n",
    "train['car_bland'] = train['car name'].apply(if_car)\n",
    "temp= pd.get_dummies(train.car_bland)\n",
    "train = pd.concat([train, temp], axis=1)\n",
    "\n",
    "test['car_bland'] = test['car name'].apply(if_car)\n",
    "temp= pd.get_dummies(test.car_bland)\n",
    "test = pd.concat([test, temp], axis=1)\n",
    "def if_car(x):\n",
    "    if \"diesel\" in x:\n",
    "        return 'diesel'\n",
    "    elif \"turbo\" in x:\n",
    "        return 'turbo'\n",
    "    elif \"sw\" in x:\n",
    "        return 'sw'\n",
    "    else:\n",
    "        return 'other_esp'\n",
    "train['car_esp'] = train['car name'].apply(if_car)\n",
    "temp= pd.get_dummies(train.car_esp)\n",
    "train = pd.concat([train, temp], axis=1)\n",
    "\n",
    "test['car_esp'] = test['car name'].apply(if_car)\n",
    "temp= pd.get_dummies(test.car_esp)\n",
    "test = pd.concat([test, temp], axis=1)\n",
    "temp= pd.get_dummies(train.origin)\n",
    "train = pd.concat([train, temp], axis=1)\n",
    "del train['origin']\n",
    "\n",
    "temp= pd.get_dummies(test.origin)\n",
    "test = pd.concat([test, temp], axis=1)\n",
    "del test['origin']\n",
    "# #------------------------------------------------------------------------------\n",
    "# # accept a dataframe, remove outliers, return cleaned data in a new dataframe\n",
    "# # see http://www.itl.nist.gov/div898/handbook/prc/section1/prc16.htm\n",
    "# #------------------------------------------------------------------------------\n",
    "# def remove_outlier(df_in, col_name):\n",
    "#     q1 = df_in[col_name].quantile(0.25)\n",
    "#     q3 = df_in[col_name].quantile(0.75)\n",
    "#     iqr = q3-q1 #Interquartile range\n",
    "#     fence_low  = q1-1.5*iqr\n",
    "#     fence_high = q3+1.5*iqr\n",
    "#     df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "#     return df_out\n",
    "\n",
    "# temp1=train[train['diesel']==1]\n",
    "# temp1=remove_outlier(temp1,'mpg')\n",
    "# temp2=train[train['turbo']==1]\n",
    "# temp2=remove_outlier(temp2,'mpg')\n",
    "# temp3=train[train['sw']==1]\n",
    "# temp3=remove_outlier(temp3,'mpg')\n",
    "# temp4=train[train['other_esp']==1]\n",
    "# temp4=remove_outlier(temp4,'mpg')\n",
    "# train = pd.concat([temp1,temp2,temp3,temp4])\n",
    "# #------------------------------------------------------------------------------\n",
    "# # accept a dataframe, remove outliers, return cleaned data in a new dataframe\n",
    "# # see http://www.itl.nist.gov/div898/handbook/prc/section1/prc16.htm\n",
    "# #------------------------------------------------------------------------------\n",
    "# def remove_outlier(df_in, col_name):\n",
    "#     q1 = df_in[col_name].quantile(0.25)\n",
    "#     q3 = df_in[col_name].quantile(0.75)\n",
    "#     iqr = q3-q1 #Interquartile range\n",
    "#     fence_low  = q1-1.5*iqr\n",
    "#     fence_high = q3+1.5*iqr\n",
    "#     df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "#     return df_out\n",
    "\n",
    "# temp1=train[train['amc']==1]\n",
    "# temp1=remove_outlier(temp1,'mpg')\n",
    "# temp2=train[train['buick']==1]\n",
    "# temp2=remove_outlier(temp2,'mpg')\n",
    "# temp3=train[train['chevrolet']==1]\n",
    "# temp3=remove_outlier(temp3,'mpg')\n",
    "# temp4=train[train['datsun']==1]\n",
    "# temp4=remove_outlier(temp4,'mpg')\n",
    "# temp5=train[train['dodge']==1]\n",
    "# temp5=remove_outlier(temp5,'mpg')\n",
    "# temp6=train[train['fiat']==1]\n",
    "# temp6=remove_outlier(temp6,'mpg')\n",
    "# temp7=train[train['ford']==1]\n",
    "# temp7=remove_outlier(temp7,'mpg')\n",
    "# temp8=train[train['mercury']==1]\n",
    "# temp8=remove_outlier(temp8,'mpg')\n",
    "# temp9=train[train['opel']==1]\n",
    "# temp9=remove_outlier(temp9,'mpg')\n",
    "# temp10=train[train['peugeot']==1]\n",
    "# temp10=remove_outlier(temp10,'mpg')\n",
    "# temp11=train[train['plymouth']==1]\n",
    "# temp11=remove_outlier(temp11,'mpg')\n",
    "# temp12=train[train['pontiac']==1]\n",
    "# temp12=remove_outlier(temp12,'mpg')\n",
    "# temp13=train[train['toyota']==1]\n",
    "# temp13=remove_outlier(temp13,'mpg')\n",
    "# temp14=train[train['volkswagen']==1]\n",
    "# temp14=remove_outlier(temp14,'mpg')\n",
    "# temp15=train[train['vw']==1]\n",
    "# temp15=remove_outlier(temp15,'mpg')\n",
    "# temp16=train[train['other_bland']==1]\n",
    "# temp16=remove_outlier(temp16,'mpg')\n",
    "# train = pd.concat([temp1,temp2,temp3,temp4,temp5,temp6,temp7,temp8,temp9,temp10,temp11,temp12,temp13,temp14,temp15,temp16])\n",
    "# temp=train['horsepower'].astype(np.float64)\n",
    "# temp=train['horsepower'].str.replace('?',train['horsepower'].mode())\n",
    "# temp['horsepower']=temp['horsepower'].replace('?',np.nan).reset_index()\n",
    "train['horsepower']=train['horsepower'].replace('?',np.nan)\n",
    "train[\"horsepower\"] = pd.to_numeric(train[\"horsepower\"], errors=\"coerce\")\n",
    "train[\"horsepower\"] = train[\"horsepower\"].fillna(train[\"horsepower\"].mean())\n",
    "# train['mpg_hie'] = pd.cut(train['mpg'], bins=np.arange(0, 100, 10), right=False)\n",
    "test['horsepower']=test['horsepower'].replace('?',np.nan)\n",
    "test[\"horsepower\"] = pd.to_numeric(test[\"horsepower\"], errors=\"coerce\")\n",
    "test[\"horsepower\"] = test[\"horsepower\"].fillna(test[\"horsepower\"].mean())\n",
    "# test['mpg_hie'] = pd.cut(train['mpg'], bins=np.arange(0, 100, 10), right=False)         \n",
    "# temp.astype(np.float64).reset_index()\n",
    "# temp\n",
    "# temp.unique()\n",
    "# train['horsepower'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['mpg']\n",
    "\n",
    "# X_train = train.drop(['id', 'mpg', 'car name'], axis=1)\n",
    "X_train = train.drop(['id', 'mpg', 'car name','car_bland','car_esp'], axis=1)\n",
    "X_test = test.drop(['id', 'car name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14     1\n",
       "66     1\n",
       "77     1\n",
       "89     1\n",
       "98     1\n",
       "      ..\n",
       "495    0\n",
       "496    0\n",
       "497    0\n",
       "498    0\n",
       "499    0\n",
       "Name: diesel, Length: 497, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['diesel'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデル\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# pipeline setting\n",
    "pipelines = {\n",
    "     'ols': Pipeline([('scl',StandardScaler()),\n",
    "                      ('est',LinearRegression())]),\n",
    "     \n",
    "     'ridge':Pipeline([('scl',StandardScaler()),\n",
    "                       ('est',Ridge(random_state=0))]),\n",
    "\n",
    "     'tree': Pipeline([('scl',StandardScaler()),\n",
    "                     ('est',DecisionTreeRegressor(random_state=0))]),\n",
    "\n",
    "     'rf': Pipeline([('scl',StandardScaler()),\n",
    "                     ('est',RandomForestRegressor(random_state=0))]),\n",
    "     \n",
    "     'gbr1': Pipeline([('scl',StandardScaler()),\n",
    "                      ('est',GradientBoostingRegressor(random_state=0))]),\n",
    "\n",
    "     'gbr2': Pipeline([('scl',StandardScaler()),\n",
    "                      ('est',GradientBoostingRegressor(n_estimators=250,\n",
    "                                                       random_state=0))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'peugeot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0a1a391a5c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    756\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy,\n\u001b[1;32m    757\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'peugeot'"
     ]
    }
   ],
   "source": [
    "#pipelineを作成するために一旦作成\n",
    "sample_pred = sample.iloc[:, 1]\n",
    "# build and evaluate\n",
    "scores = {}\n",
    "for pipe_name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y)\n",
    "    scores[(pipe_name,'train')] = r2_score(y, pipeline.predict(X_train))\n",
    "    scores[(pipe_name,'test')] = r2_score(sample_pred, pipeline.predict(X_test))\n",
    "\n",
    "print(pd.Series(scores).unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=6,\n",
       "                          max_features='sqrt', max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=52, min_samples_split=5,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=0.8, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "    min_samples_split = 5, \n",
    "    min_samples_leaf = 52, \n",
    "    max_depth = 6, \n",
    "    max_features = 'sqrt', \n",
    "    subsample = 0.8)\n",
    "\n",
    "model.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測\n",
    "pred = model.predict(X_test)\n",
    "sample[1] = pred\n",
    "sample.to_csv('GradientBoostingRegressor.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=6,\n",
       "                                                 max_features='sqrt',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=52,\n",
       "                                                 min_samples_split=5,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_i...\n",
       "             param_grid={'learning_rate': [0.05, 0.060000000000000005, 0.07,\n",
       "                                           0.08000000000000002,\n",
       "                                           0.09000000000000001, 0.1,\n",
       "                                           0.11000000000000001,\n",
       "                                           0.12000000000000001, 0.13, 0.14,\n",
       "                                           0.15000000000000002,\n",
       "                                           0.16000000000000003,\n",
       "                                           0.17000000000000004,\n",
       "                                           0.18000000000000005, 0.19, 0.2],\n",
       "                         'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'n_estimators': list(range(20, 101, 10)),\n",
    "             'learning_rate': list(np.arange(0.05, 0.20, 0.01))}\n",
    "# scoringを neg_mean_squared_error(負のMSE)とする\n",
    "gsearch1 = GridSearchCV(estimator = model, \n",
    "                        param_grid = param, \n",
    "                        cv = 5, \n",
    "                        n_jobs=4, \n",
    "                        scoring = 'neg_mean_squared_error')\n",
    "\n",
    "\n",
    "#fitさせる\n",
    "gsearch1.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.19, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# test精度の平均が最も高かった組み合わせを出力\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測\n",
    "pred_gsearch = gsearch1.predict(X_test)\n",
    "\n",
    "sample[1] = pred_gsearch\n",
    "sample.to_csv('GBR_pred_gsearch.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators'  : [10, 100, 500, 2000], 'n_jobs': [-1]}\n",
    "\n",
    "# モデルにインスタンス生成\n",
    "mod = RandomForestRegressor()\n",
    "\n",
    "# ハイパーパラメータ探索\n",
    "cv = GridSearchCV(mod, params, cv = 10, scoring= 'neg_mean_squared_error', n_jobs =1)\n",
    "cv.fit(X_train, y)\n",
    "\n",
    "# 予測\n",
    "pred_cv = cv.predict(X_test)\n",
    "\n",
    "sample[1] = pred_cv\n",
    "sample.to_csv('RFR_gridserch.csv', index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
